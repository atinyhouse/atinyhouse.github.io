#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å³åˆ»åŠ¨æ€è‡ªåŠ¨åŒæ­¥è„šæœ¬ V2
ä½¿ç”¨å³åˆ» GraphQL API è·å–åŠ¨æ€å¹¶åŒæ­¥åˆ°åšå®¢

ä½¿ç”¨æ–¹æ³•ï¼š
1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   export JIKE_ACCESS_TOKEN="your_access_token"
   export JIKE_USER_ID="71A6B3C3-1382-4121-A17A-2A4C05CB55E8"

2. è¿è¡Œè„šæœ¬ï¼š
   python scripts/sync_jike_v2.py

ä½œè€…: Claude Code
æ›´æ–°æ—¶é—´: 2025-10-25
"""

import requests
import json
import yaml
from datetime import datetime
import os
import sys
from pathlib import Path
import time
import hashlib
from urllib.parse import urlparse

# ============================================
# é…ç½®
# ============================================

# å³åˆ»ç”¨æˆ· IDï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è·å–ï¼‰
USER_ID = os.getenv('JIKE_USER_ID', '71A6B3C3-1382-4121-A17A-2A4C05CB55E8')

# å³åˆ» GraphQL API ç«¯ç‚¹
JIKE_API = "https://web-api.okjike.com/api/graphql"

# å›¾ç‰‡ä¿å­˜ç›®å½•
IMAGES_DIR = "_pages/files/thoughts"

# æ¯æ¬¡è·å–çš„æ•°é‡
FETCH_LIMIT = 50

# ============================================
# å³åˆ» API è°ƒç”¨
# ============================================

def get_jike_token():
    """ä»ç¯å¢ƒå˜é‡è·å–å³åˆ» token"""
    token = os.getenv('JIKE_ACCESS_TOKEN')
    if not token:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® JIKE_ACCESS_TOKEN ç¯å¢ƒå˜é‡")
        print("\nè¯·å…ˆè®¾ç½®ï¼š")
        print("  export JIKE_ACCESS_TOKEN='your_token'")
        print("\nè·å– token çš„æ–¹æ³•ï¼š")
        print("  1. è®¿é—® https://web.okjike.com")
        print("  2. ç™»å½•è´¦å·")
        print("  3. æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…· (F12)")
        print("  4. åœ¨ Network æ ‡ç­¾ä¸­æ‰¾åˆ°ä»»æ„ API è¯·æ±‚")
        print("  5. æŸ¥çœ‹ Request Headers ä¸­çš„ x-jike-access-token")
        sys.exit(1)
    return token

def fetch_user_posts(token, user_id, limit=50, load_more_key=None):
    """
    ä½¿ç”¨ GraphQL è·å–ç”¨æˆ·åŠ¨æ€
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Accept': 'application/json',
        'Content-Type': 'application/json',
        'x-jike-access-token': token,
    }

    # GraphQL æŸ¥è¯¢
    query = """
    query GetUserProfile($username: String!) {
      userProfile(username: $username) {
        username
        screenName
        briefIntro
        feeds(limit: 50, loadMoreKey: null) {
          nodes {
            ... on OriginalPost {
              id
              type
              content
              createdAt
              pictures {
                picUrl
                thumbnailUrl
              }
              urlsInText {
                url
                title
              }
              topic {
                content
              }
            }
            ... on Repost {
              id
              type
              content
              createdAt
              target {
                ... on OriginalPost {
                  content
                  pictures {
                    picUrl
                    thumbnailUrl
                  }
                }
              }
            }
          }
          pageInfo {
            loadMoreKey
            hasNextPage
          }
        }
      }
    }
    """

    variables = {
        "username": user_id
    }

    payload = {
        "operationName": "GetUserProfile",
        "query": query,
        "variables": variables
    }

    try:
        response = requests.post(
            JIKE_API,
            headers=headers,
            json=payload,
            timeout=30
        )
        response.raise_for_status()
        data = response.json()

        if 'errors' in data:
            print(f"âŒ API é”™è¯¯: {data['errors']}")
            return None, None

        user_profile = data.get('data', {}).get('userProfile', {})
        feeds = user_profile.get('feeds', {})
        nodes = feeds.get('nodes', [])
        page_info = feeds.get('pageInfo', {})

        return nodes, page_info.get('loadMoreKey')

    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None, None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        print(f"å“åº”å†…å®¹: {response.text[:500]}")
        return None, None

# ============================================
# æ•°æ®è§£æ
# ============================================

def parse_post(post):
    """
    è§£æå³åˆ»åŠ¨æ€æ•°æ®
    """
    thought = {}

    # æ—¥æœŸæ—¶é—´
    created_at = post.get('createdAt')
    if created_at:
        # å¤„ç†æ—¶é—´æ ¼å¼
        try:
            # ç§»é™¤æ¯«ç§’éƒ¨åˆ†çš„å¤šä½™ä½æ•°
            if '.' in created_at:
                parts = created_at.split('.')
                created_at = parts[0] + '.' + parts[1][:6] + parts[1][-1]

            dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8)
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            dt_beijing = dt.astimezone(beijing_tz)

            thought['date'] = dt_beijing.strftime('%Y-%m-%d')
            thought['time'] = dt_beijing.strftime('%H:%M')
        except Exception as e:
            print(f"âš ï¸  æ—¶é—´è§£æå¤±è´¥: {created_at}, é”™è¯¯: {e}")
            return None

    # å†…å®¹
    content = post.get('content', '').strip()

    # å¦‚æœæ˜¯è½¬å‘ï¼Œè·å–åŸå§‹å†…å®¹
    if post.get('type') == 'REPOST':
        target = post.get('target', {})
        if target:
            original_content = target.get('content', '')
            if content and original_content:
                content = f"{content}\n\n// è½¬å‘ï¼š\n{original_content}"
            elif original_content:
                content = original_content

    if content:
        thought['content'] = content

    # å›¾ç‰‡
    pictures = post.get('pictures', [])
    if not pictures and post.get('type') == 'REPOST':
        target = post.get('target', {})
        pictures = target.get('pictures', [])

    if pictures:
        # åªä¿ç•™å›¾ç‰‡ URLï¼Œç¨åä¸‹è½½
        thought['images_urls'] = []
        for pic in pictures:
            pic_url = pic.get('picUrl') or pic.get('thumbnailUrl')
            if pic_url:
                thought['images_urls'].append(pic_url)

    # é“¾æ¥
    urls = post.get('urlsInText', [])
    if urls:
        url = urls[0].get('url')
        title = urls[0].get('title', 'æŸ¥çœ‹é“¾æ¥')
        if url:
            thought['link'] = url
            thought['link_title'] = title

    # è¯é¢˜
    topic = post.get('topic')
    if topic:
        topic_name = topic.get('content', '')
        if topic_name:
            thought['topic'] = topic_name

    # åŠ¨æ€ IDï¼ˆç”¨äºå»é‡ï¼‰
    post_id = post.get('id')
    if post_id:
        thought['id'] = post_id

    return thought if 'content' in thought or 'images_urls' in thought else None

# ============================================
# å›¾ç‰‡ä¸‹è½½
# ============================================

def download_image(url, save_dir):
    """
    ä¸‹è½½å›¾ç‰‡å¹¶è¿”å›æœ¬åœ°è·¯å¾„
    """
    try:
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨ URL çš„ hashï¼‰
        url_hash = hashlib.md5(url.encode()).hexdigest()[:16]
        ext = os.path.splitext(urlparse(url).path)[1] or '.jpg'
        filename = f"{url_hash}{ext}"
        filepath = os.path.join(save_dir, filename)

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if os.path.exists(filepath):
            return f"/{filepath}"

        # ä¸‹è½½å›¾ç‰‡
        response = requests.get(url, timeout=30, stream=True)
        response.raise_for_status()

        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        return f"/{filepath}"

    except Exception as e:
        print(f"âš ï¸  å›¾ç‰‡ä¸‹è½½å¤±è´¥: {url}, é”™è¯¯: {e}")
        return url  # ä¸‹è½½å¤±è´¥åˆ™ä½¿ç”¨åŸå§‹ URL

# ============================================
# æ•°æ®ç®¡ç†
# ============================================

def load_existing_thoughts(file_path):
    """åŠ è½½ç°æœ‰çš„ thoughts æ•°æ®"""
    if not os.path.exists(file_path):
        return []

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            # è·³è¿‡æ³¨é‡Šè¡Œ
            content = []
            for line in f:
                if not line.strip().startswith('#'):
                    content.append(line)

            if not content:
                return []

            data = yaml.safe_load(''.join(content))
            return data if isinstance(data, list) else []
    except Exception as e:
        print(f"âš ï¸  è¯»å–ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return []

def merge_thoughts(existing, new_thoughts):
    """
    åˆå¹¶æ–°æ—§æ•°æ®ï¼Œå»é‡å¹¶æŒ‰æ—¶é—´æ’åº
    """
    # åˆ›å»º ID åˆ° thought çš„æ˜ å°„
    thought_map = {}

    # å…ˆæ·»åŠ ç°æœ‰æ•°æ®
    for thought in existing:
        # ä½¿ç”¨ date + time + content çš„å‰50å­—ç¬¦ä½œä¸ºå”¯ä¸€æ ‡è¯†
        key = f"{thought.get('date')}_{thought.get('time')}_{thought.get('content', '')[:50]}"
        thought_map[key] = thought

    # æ·»åŠ æ–°æ•°æ®
    new_count = 0
    for thought in new_thoughts:
        key = f"{thought.get('date')}_{thought.get('time')}_{thought.get('content', '')[:50]}"
        if key not in thought_map:
            thought_map[key] = thought
            new_count += 1

    # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ—¥æœŸæ—¶é—´æ’åº
    all_thoughts = list(thought_map.values())
    all_thoughts.sort(
        key=lambda x: f"{x.get('date', '9999-99-99')} {x.get('time', '99:99')}",
        reverse=True
    )

    return all_thoughts, new_count

def save_thoughts(thoughts, file_path):
    """ä¿å­˜ thoughts æ•°æ®"""
    # åˆ›å»ºæ–‡ä»¶å¤´éƒ¨
    header = f"""# ============================================
# Thoughts æ•°æ®æ–‡ä»¶ - å³åˆ»åŠ¨æ€
# ============================================
#
# æœ¬æ–‡ä»¶ç”± sync_jike_v2.py è‡ªåŠ¨ç”Ÿæˆ
# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
#
# ä½¿ç”¨è¯´æ˜ï¼š
# 1. æ¯æ¡åŠ¨æ€ä»¥ "- date:" å¼€å¤´
# 2. content æ”¯æŒ Markdown æ ¼å¼
# 3. å›¾ç‰‡å·²è‡ªåŠ¨ä¿å­˜åˆ° _pages/files/thoughts/ ç›®å½•
# 4. æ•°æ®ä¼šè‡ªåŠ¨æŒ‰æ—¥æœŸå€’åºæ’åˆ—ï¼ŒæŒ‰æœˆä»½åˆ†ç»„æ˜¾ç¤º
#
# ============================================

"""

    # ä¿å­˜æ–‡ä»¶
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(header)
            # æ¸…ç†æ•°æ®ä¸­çš„ä¸´æ—¶å­—æ®µ
            clean_thoughts = []
            for thought in thoughts:
                clean_thought = {k: v for k, v in thought.items() if k != 'images_urls' and k != 'id'}
                clean_thoughts.append(clean_thought)

            yaml.dump(
                clean_thoughts,
                f,
                allow_unicode=True,
                sort_keys=False,
                default_flow_style=False,
                width=1000
            )

        print(f"âœ… æˆåŠŸä¿å­˜ {len(thoughts)} æ¡åŠ¨æ€åˆ° {file_path}")
        return True

    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return False

# ============================================
# ä¸»æµç¨‹
# ============================================

def main():
    print("="*60)
    print("ğŸš€ å³åˆ»åŠ¨æ€åŒæ­¥è„šæœ¬ V2")
    print("="*60)
    print()

    # è·å– token
    token = get_jike_token()
    print(f"âœ“ Token: {token[:10]}...{token[-10:]}")
    print(f"âœ“ ç”¨æˆ· ID: {USER_ID}")
    print()

    # è·å–åŠ¨æ€
    print("ğŸ“¥ å¼€å§‹è·å–å³åˆ»åŠ¨æ€...")
    posts, load_more_key = fetch_user_posts(token, USER_ID, limit=FETCH_LIMIT)

    if posts is None:
        print("\nâŒ è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("  1. Token æ˜¯å¦æ­£ç¡®")
        print("  2. ç”¨æˆ· ID æ˜¯å¦æ­£ç¡®")
        print("  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        sys.exit(1)

    if not posts:
        print("âš ï¸  æ²¡æœ‰è·å–åˆ°ä»»ä½•åŠ¨æ€")
        sys.exit(0)

    print(f"âœ“ æˆåŠŸè·å– {len(posts)} æ¡åŠ¨æ€")
    print()

    # è§£æåŠ¨æ€
    print("ğŸ”„ è§£æåŠ¨æ€æ•°æ®...")
    new_thoughts = []
    for post in posts:
        thought = parse_post(post)
        if thought:
            new_thoughts.append(thought)

    print(f"âœ“ æˆåŠŸè§£æ {len(new_thoughts)} æ¡æœ‰æ•ˆåŠ¨æ€")
    print()

    # ä¸‹è½½å›¾ç‰‡
    print("ğŸ“· ä¸‹è½½å›¾ç‰‡...")
    for thought in new_thoughts:
        if 'images_urls' in thought:
            images = []
            for url in thought['images_urls']:
                local_path = download_image(url, IMAGES_DIR)
                images.append(local_path)
                print(f"  âœ“ {os.path.basename(local_path)}")

            thought['images'] = images
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«

    print()

    # åŠ è½½ç°æœ‰æ•°æ®
    script_dir = Path(__file__).parent
    project_dir = script_dir.parent
    data_file = project_dir / '_data' / 'thoughts.yml'

    print("ğŸ“‚ è¯»å–ç°æœ‰æ•°æ®...")
    existing_thoughts = load_existing_thoughts(data_file)
    print(f"âœ“ ç°æœ‰ {len(existing_thoughts)} æ¡åŠ¨æ€")
    print()

    # åˆå¹¶æ•°æ®
    print("ğŸ”— åˆå¹¶æ•°æ®...")
    all_thoughts, new_count = merge_thoughts(existing_thoughts, new_thoughts)
    print(f"âœ“ åˆå¹¶å®Œæˆ: æ€»å…± {len(all_thoughts)} æ¡ï¼Œæ–°å¢ {new_count} æ¡")
    print()

    # ä¿å­˜æ•°æ®
    print("ğŸ’¾ ä¿å­˜æ•°æ®...")
    if save_thoughts(all_thoughts, data_file):
        print()
        print("="*60)
        print("âœ… åŒæ­¥å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡: æ€»è®¡ {len(all_thoughts)} æ¡ï¼Œæœ¬æ¬¡æ–°å¢ {new_count} æ¡")
        print()
        print("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
        print("  1. è¿è¡Œ 'bundle exec jekyll serve' é¢„è§ˆ")
        print("  2. è®¿é—® http://localhost:4000/thoughts/ æŸ¥çœ‹æ•ˆæœ")
        print("="*60)
    else:
        print("\nâŒ åŒæ­¥å¤±è´¥")
        sys.exit(1)

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
