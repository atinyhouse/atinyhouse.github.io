#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å³åˆ»åŠ¨æ€è‡ªåŠ¨åŒæ­¥ - æœ€ç»ˆç‰ˆæœ¬
ä½¿ç”¨ RSSHub å…¬å…±æœåŠ¡ï¼Œå®Œå…¨è‡ªåŠ¨åŒ–

ç‰¹ç‚¹ï¼š
- ä¸éœ€è¦ Token
- ä¸éœ€è¦ç™»å½•
- å®Œå…¨è‡ªåŠ¨åŒ–
- å¯é ç¨³å®š
"""

import urllib.request
import json
import yaml
from datetime import datetime
import os
import re
import xml.etree.ElementTree as ET
from html.parser import HTMLParser
from urllib.parse import urlparse
import hashlib

class HTMLStripper(HTMLParser):
    """ç§»é™¤ HTML æ ‡ç­¾"""
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs= True
        self.text = []

    def handle_data(self, d):
        self.text.append(d)

    def get_text(self):
        return ''.join(self.text)

def strip_html(html):
    """æ¸…ç† HTML æ ‡ç­¾"""
    s = HTMLStripper()
    s.feed(html)
    return s.get_text()

def extract_images_from_description(description_text):
    """ä» description ä¸­æå–å›¾ç‰‡ URL"""
    if not description_text:
        return []

    # æŸ¥æ‰¾æ‰€æœ‰ img æ ‡ç­¾ä¸­çš„ src
    img_pattern = r'<img[^>]+src=["\']([^"\']+)["\']'
    images = re.findall(img_pattern, description_text)

    # è¿‡æ»¤æ‰éå›¾ç‰‡é“¾æ¥
    valid_images = []
    for img in images:
        # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡ URL
        if img and (img.startswith('http') or img.startswith('//')):
            # å¦‚æœæ˜¯åè®®ç›¸å¯¹ URLï¼Œè¡¥å…¨åè®®
            if img.startswith('//'):
                img = 'https:' + img
            valid_images.append(img)

    return valid_images

def download_image(url, save_path):
    """ä¸‹è½½å›¾ç‰‡ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Referer': 'https://m.okjike.com/'
        }
        req = urllib.request.Request(url, headers=headers)

        with urllib.request.urlopen(req, timeout=30) as response:
            data = response.read()

            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ•°æ®ï¼ˆä¸æ˜¯ JSON é”™è¯¯ï¼‰
            if len(data) < 100:
                # å¯èƒ½æ˜¯é”™è¯¯å“åº”
                try:
                    json_data = json.loads(data)
                    if 'error' in json_data:
                        print(f"    âœ— å›¾ç‰‡è·å–å¤±è´¥: {json_data.get('error')}")
                        return False
                except:
                    pass

            # ä¿å­˜å›¾ç‰‡
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with open(save_path, 'wb') as f:
                f.write(data)

            return True

    except Exception as e:
        print(f"    âœ— ä¸‹è½½å¤±è´¥: {e}")
        return False

USER_ID = "71A6B3C3-1382-4121-A17A-2A4C05CB55E8"

# å¤šä¸ª RSSHub é•œåƒæºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
RSSHUB_INSTANCES = [
    "https://rsshub.app",
    "https://rss.miantiao.me",
    "https://rss.shab.fun",
    "https://rsshub.rssforever.com",
]

print("="*60)
print("ğŸš€ å³åˆ»åŠ¨æ€è‡ªåŠ¨åŒæ­¥")
print("="*60)
print()
print(f"ç”¨æˆ· ID: {USER_ID}")
print(f"å¯ç”¨é•œåƒ: {len(RSSHUB_INSTANCES)} ä¸ª")
print()

# å°è¯•ä»å¤šä¸ªæºè·å– RSS
print("ğŸ“¡ æ­£åœ¨è·å– RSS feed...")
rss_data = None
successful_source = None

for instance in RSSHUB_INSTANCES:
    rsshub_url = f"{instance}/jike/user/{USER_ID}"
    print(f"  å°è¯•: {instance}")

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        req = urllib.request.Request(rsshub_url, headers=headers)

        with urllib.request.urlopen(req, timeout=15) as response:
            rss_data = response.read().decode('utf-8')
            successful_source = instance
            print(f"  âœ“ æˆåŠŸè·å–æ•°æ®")
            break

    except Exception as e:
        print(f"  âœ— å¤±è´¥: {e}")
        continue

if rss_data is None:
    print()
    print("âŒ æ‰€æœ‰ RSS æºéƒ½ä¸å¯ç”¨")
    print()
    print("è¿™é€šå¸¸æ˜¯æš‚æ—¶æ€§é—®é¢˜ï¼Œå¯èƒ½çš„åŸå› ï¼š")
    print("  - RSSHub æœåŠ¡å™¨ç»´æŠ¤")
    print("  - ç½‘ç»œè¿æ¥é—®é¢˜")
    print("  - å³åˆ» API æš‚æ—¶ä¸å¯ç”¨")
    print()
    print("ğŸ’¡ å»ºè®®ï¼š")
    print("  - ç¨åä¼šè‡ªåŠ¨é‡è¯•ï¼ˆæ¯å¤© 19:15ï¼‰")
    print("  - æ‚¨çš„å†å²æ•°æ®å·²ä¿å­˜ï¼Œä¸ä¼šä¸¢å¤±")
    print("  - å¯ä»¥ç¨åæ‰‹åŠ¨è§¦å‘ workflow")
    print()
    # åœ¨ GitHub Actions ä¸­ä¼˜é›…é€€å‡ºï¼Œé¿å…æ˜¾ç¤ºä¸ºå¤±è´¥
    import sys
    if os.getenv('GITHUB_ACTIONS'):
        print("âš ï¸  GitHub Actions: ä¼˜é›…é€€å‡ºï¼Œç­‰å¾…ä¸‹æ¬¡é‡è¯•")
        sys.exit(0)
    else:
        sys.exit(1)

print(f"âœ“ ä½¿ç”¨æ•°æ®æº: {successful_source}")
print()

# è§£æ RSS
print("ğŸ”„ è§£æ RSS æ•°æ®...")
try:
    root = ET.fromstring(rss_data)

    # æ‰¾åˆ°æ‰€æœ‰ item
    items = root.findall('.//item')

    if not items:
        print("âš ï¸  RSS ä¸­æ²¡æœ‰æ‰¾åˆ°åŠ¨æ€")
        exit(0)

    print(f"âœ“ æ‰¾åˆ° {len(items)} æ¡åŠ¨æ€")

except Exception as e:
    print(f"âŒ RSS è§£æå¤±è´¥: {e}")
    exit(1)

print()

# è½¬æ¢ä¸º thoughts æ ¼å¼
print("ğŸ“ è½¬æ¢æ•°æ®æ ¼å¼...")
new_thoughts = []
total_images = 0

# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(__file__))
images_dir = os.path.join(project_root, 'assets', 'thoughts')

for item in items:
    thought = {}

    # æ—¥æœŸæ—¶é—´
    pub_date = item.find('pubDate')
    if pub_date is not None and pub_date.text:
        try:
            # è§£æ RSS æ—¥æœŸæ ¼å¼: Mon, 25 Oct 2025 10:30:00 +0800
            from email.utils import parsedate_to_datetime
            dt = parsedate_to_datetime(pub_date.text)
            thought['date'] = dt.strftime('%Y-%m-%d')
            thought['time'] = dt.strftime('%H:%M')
            # ç”Ÿæˆå”¯ä¸€ ID ç”¨äºå›¾ç‰‡æ–‡ä»¶å
            thought_id = dt.strftime('%Y%m%d%H%M%S')
        except:
            pass

    # å†…å®¹å’Œå›¾ç‰‡
    description = item.find('description')
    if description is not None and description.text:
        description_text = description.text

        # æå–å›¾ç‰‡
        image_urls = extract_images_from_description(description_text)
        if image_urls:
            print(f"  [{thought.get('date')} {thought.get('time')}] æ‰¾åˆ° {len(image_urls)} å¼ å›¾ç‰‡")
            images = []

            for idx, img_url in enumerate(image_urls, 1):
                # ç”Ÿæˆæ–‡ä»¶å
                img_ext = os.path.splitext(urlparse(img_url).path)[1] or '.jpg'
                img_filename = f"{thought_id}-img{idx}{img_ext}"
                img_path = os.path.join(images_dir, img_filename)

                # ä¸‹è½½å›¾ç‰‡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if not os.path.exists(img_path):
                    print(f"    ä¸‹è½½å›¾ç‰‡ {idx}/{len(image_urls)}...")
                    if download_image(img_url, img_path):
                        images.append(f"/assets/thoughts/{img_filename}")
                        total_images += 1
                        print(f"    âœ“ å·²ä¿å­˜: {img_filename}")
                else:
                    images.append(f"/assets/thoughts/{img_filename}")
                    print(f"    âœ“ å·²å­˜åœ¨: {img_filename}")

            if images:
                thought['images'] = images

        # æå–æ–‡æœ¬å†…å®¹
        content = strip_html(description_text)
        content = re.sub(r'\s+', ' ', content).strip()
        if content:
            thought['content'] = content

    # æ ‡é¢˜
    title = item.find('title')
    if title is not None and title.text:
        title_text = title.text.strip()
        # å¦‚æœæ ‡é¢˜ä¸æ˜¯å†…å®¹çš„å¼€å¤´éƒ¨åˆ†ï¼Œåˆ™ä½œä¸ºè¯é¢˜
        content = thought.get('content', '')
        if title_text and content and not content.startswith(title_text[:20]):
            thought['topic'] = title_text

    # é“¾æ¥
    link = item.find('link')
    if link is not None and link.text:
        thought['source_link'] = link.text

    if 'date' in thought and 'content' in thought:
        new_thoughts.append(thought)

print(f"âœ“ æˆåŠŸè½¬æ¢ {len(new_thoughts)} æ¡åŠ¨æ€")
if total_images > 0:
    print(f"âœ“ ä¸‹è½½äº† {total_images} å¼ æ–°å›¾ç‰‡")
print()

# è¯»å–ç°æœ‰æ•°æ®
data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), '_data')
output_file = os.path.join(data_dir, 'thoughts.yml')

print(f"ğŸ“‚ è¯»å–ç°æœ‰æ•°æ®...")

existing_thoughts = []
if os.path.exists(output_file):
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            lines = []
            for line in f:
                if not line.strip().startswith('#'):
                    lines.append(line)

            if lines:
                existing_thoughts = yaml.safe_load(''.join(lines)) or []

        print(f"âœ“ è¯»å–åˆ° {len(existing_thoughts)} æ¡ç°æœ‰åŠ¨æ€")
    except Exception as e:
        print(f"âš ï¸  è¯»å–å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶: {e}")
else:
    print("âœ“ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")

print()

# åˆå¹¶å»é‡
print("ğŸ”— åˆå¹¶æ•°æ®...")

# ä½¿ç”¨ source_link ä½œä¸ºä¸»è¦å”¯ä¸€æ ‡è¯†ï¼ˆæœ€å¯é ï¼‰
# å¦‚æœæ²¡æœ‰ source_linkï¼Œåˆ™ç”¨å†…å®¹ä½œä¸ºæ ‡è¯†
existing_keys = {}  # key -> thought
for t in existing_thoughts:
    source_link = t.get('source_link', '')
    if source_link:
        key = f"link:{source_link}"
    else:
        # å¯¹äºæ²¡æœ‰ source_link çš„ï¼Œç”¨æ—¥æœŸ+æ—¶é—´+å†…å®¹å‰100å­—ç¬¦
        content = ''.join(str(t.get('content', '')).split())[:100]
        key = f"content:{t.get('date', '')}_{t.get('time', '')}_{content}"
    existing_keys[key] = t

new_count = 0
for t in new_thoughts:
    # ç¡®ä¿æ—¶é—´æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ˆé˜²æ­¢ YAML è§£æé—®é¢˜ï¼‰
    if 'time' in t:
        t['time'] = str(t['time'])

    source_link = t.get('source_link', '')
    if source_link:
        key = f"link:{source_link}"
    else:
        content = ''.join(str(t.get('content', '')).split())[:100]
        key = f"content:{t.get('date', '')}_{t.get('time', '')}_{content}"

    if key not in existing_keys:
        existing_thoughts.append(t)
        existing_keys[key] = t
        new_count += 1

# æŒ‰æ—¥æœŸæ—¶é—´å€’åºæ’åˆ—
existing_thoughts.sort(
    key=lambda x: (x.get('date', '0000-00-00'), x.get('time', '00:00')),
    reverse=True
)

print(f"âœ“ åˆå¹¶å®Œæˆ")
print(f"  æ€»è®¡: {len(existing_thoughts)} æ¡")
print(f"  æ–°å¢: {new_count} æ¡")
print()

# ä¿å­˜
print("ğŸ’¾ ä¿å­˜æ•°æ®...")

os.makedirs(data_dir, exist_ok=True)

# ç¡®ä¿æ‰€æœ‰æ—¶é—´å­—æ®µéƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
for thought in existing_thoughts:
    if 'time' in thought and thought['time'] is not None:
        thought['time'] = str(thought['time'])

header = f"""# ============================================
# Thoughts æ•°æ®æ–‡ä»¶ - å³åˆ»åŠ¨æ€
# ============================================
#
# æœ¬æ–‡ä»¶ç”± sync_jike_simple.py è‡ªåŠ¨ç”Ÿæˆ
# æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# æ•°æ®æ¥æº: RSSHub (https://rsshub.app)
#
# ============================================

"""

# è‡ªå®šä¹‰ YAML representerï¼Œç¡®ä¿æ—¶é—´å­—æ®µç”¨å¼•å·
def str_representer(dumper, data):
    """ç¡®ä¿æ—¶é—´æ ¼å¼çš„å­—ç¬¦ä¸²ç”¨å¼•å·åŒ…è£¹"""
    if ':' in str(data) and len(str(data)) <= 8:  # å¯èƒ½æ˜¯æ—¶é—´æ ¼å¼
        return dumper.represent_scalar('tag:yaml.org,2002:str', str(data), style="'")
    return dumper.represent_scalar('tag:yaml.org,2002:str', data)

yaml.add_representer(str, str_representer)

try:
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(header)
        yaml.dump(
            existing_thoughts,
            f,
            allow_unicode=True,
            sort_keys=False,
            default_flow_style=False,
            width=float('inf')
        )

    print(f"âœ“ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")

except Exception as e:
    print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    exit(1)

print()
print("="*60)
print("âœ… åŒæ­¥å®Œæˆï¼")
print("="*60)
print()
print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
print(f"  - RSS è·å–: {len(items)} æ¡")
print(f"  - æœ‰æ•ˆæ•°æ®: {len(new_thoughts)} æ¡")
print(f"  - æ–°å¢åŠ¨æ€: {new_count} æ¡")
print(f"  - ä¸‹è½½å›¾ç‰‡: {total_images} å¼ ")
print(f"  - æ€»è®¡åŠ¨æ€: {len(existing_thoughts)} æ¡")
print()

if new_count > 0:
    print(f"ğŸ‰ å‘ç° {new_count} æ¡æ–°åŠ¨æ€ï¼")
    print()
    print("æœ€æ–°åŠ¨æ€é¢„è§ˆ:")
    for i, t in enumerate(new_thoughts[:3], 1):
        content_preview = t.get('content', '')[:60]
        print(f"  {i}. [{t.get('date')} {t.get('time')}] {content_preview}...")
else:
    print("âœ“ æ²¡æœ‰æ–°åŠ¨æ€")

print()
print("ğŸ’¡ ä¸‹ä¸€æ­¥:")
print("  - æœ¬åœ°é¢„è§ˆ: bundle exec jekyll serve")
print("  - è®¿é—®: http://localhost:4000/thoughts/")
